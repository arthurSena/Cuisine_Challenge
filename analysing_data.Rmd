---
title: "What’s Cooking?"
author: "Arthur Sena"
date: "September 18, 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(ggplot2)
library(jsonlite)
library(dplyr)
library(tm)
library(neuralnet)
library(nnet)
library(caret)
```

#Analisando nossos dados

Antes de qualquer coisa, precisamos saber com que tipo de dados nós estamos lidando aqui. No caso, temos um arquivo 'json' de 12MB  contendo uma lista com a descrição de 39774 pratos de comidas. Para cada um desses pratos de comidas temos uma lista de ingredientes e um determinado ID. Abaixo é possível visualizar uma porção dos nossos dados.

```{r,warning=FALSE}
  train <- fromJSON("/home/arthur/Documentos/Cuisine_Challenge/train.json")
  head(train)
```


Vamos agora analisar o quão bem distribuído se encontra nossos dados.

```{r,warning=FALSE}
  c <- ggplot(train, aes(factor(cuisine)))
  c + geom_bar()
```

Pelo gráfico acima, vemos que temos muitos pratos italianos e mexicanos nos nossos dados.

#Primeira Abordagem
Minha primeira idéia pra resolver tal problema é criar um 'dataset' que contenha 'n' colunas representando cada ingrediente encontrado no 'dataset' de treino e uma variável 'target' como rótulo. Contudo, essa idéia é inviável visto que eu tenho mais de 6 mil diferentes tipos de ingredientes, ou seja, precisaria de um 'dataset' com essa mesma quantidade de colunas :(

Uma simples abordagem pra tentar resolver esse problema é tentar filtrar essa quantidade de ingredientes e tentar trabalhar com os ingredientes que se encontram mais presentes nos nossos dados.

```{r, warning=F}

brasil <-train[train$cuisine == 'brazilian',]

```


#teste
```{r,warning=F}

ingred_freq_by_cuisine <- read.csv("~/Documents/redes_neurais/cuisine/ingred_freq_by_cuisine.csv", header=FALSE)
colnames(ingred_freq_by_cuisine) <- c("cuisine","ingredient","freq")
ingred_freq_by_cuisine$freq <- as.numeric(ingred_freq_by_cuisine$freq)
ingred_freq_by_cuisine<-ingred_freq_by_cuisine %>% arrange(cuisine,desc(freq))

length(unique(ingred_freq_by_cuisine$ingredient))

ingred_freq_by_cuisine_20 <- read.csv("~/Documents/redes_neurais/cuisine/ingred_freq_by_cuisine_20.csv", header=FALSE)
colnames(ingred_freq_by_cuisine_20) <- c("cuisine","ingredient","freq")
length(unique(ingred_freq_by_cuisine_20$ingredient))

ingred_freq_by_cuisine_100 <- read.csv("~/Documents/redes_neurais/cuisine/ingred_freq_by_cuisine_100.csv", header=FALSE)
colnames(ingred_freq_by_cuisine_100) <- c("cuisine","ingredient","freq")
length(unique(ingred_freq_by_cuisine_100$ingredient))

ing100 <- unique(ingred_freq_by_cuisine_100$ingredient)

save(as.list(ing100),file = "most_100.csv")






```

```{r}

#Usando Single Hidden Layer Neural Network
train_100_freq_ingred <- read.csv("~/Documents/redes_neurais/cuisine/train_100_freq_ingred.csv")
train_100_freq_ingred <- read.csv("~/Documentos/Cuisine_Challenge/train_100_freq_ingred.csv")

index<-createDataPartition(train_100_freq_ingred$target,p=0.7,list=FALSE)
train100<-train_100_freq_ingred[index,]
test100<-train_100_freq_ingred[-index,]

train.nnet<-nnet(target~.,train100,size=20,rang=0.07,Hess=FALSE,decay=0.01,maxit=250, MaxNWts = 7400)

require(RCurl)
root.url<-'https://gist.githubusercontent.com/fawda123'
raw.fun<-paste(
  root.url,
  '5086859/raw/cc1544804d5027d82b70e74b83b3941cd2184354/nnet_plot_fun.r',
  sep='/'
  )
script<-getURL(raw.fun, ssl.verifypeer = FALSE)
eval(parse(text = script))
rm('script','raw.fun')

plot(train.nnet,pos.col='darkgreen',neg.col='darkblue',alpha.val=0.7,rel.rsc=15,
circle.cex=10,cex=1.4,
    circle.col='brown')

test.nnet<-predict(train.nnet,test100,type=("class"))

View(table(test100$target,test.nnet))

confusionMatrix(table(test100$target,test.nnet))

#Single Layer com Caret

model <- train(target~., train100, method='nnet', linout=TRUE, trace = FALSE,
                #Grid of tuning parameters to try:
                tuneGrid=expand.grid(.size=c(20,30,40),.decay=c(0,0.001,0.1))) 



#Usando neuralnetwork

trainData <- cbind(train100[, 1:348], class.ind(train100$target))

temp <-""
for (c in 1:length(levels(train_100_freq_ingred$target))){
  if (c == 1){
    temp = paste(temp, levels(train_100_freq_ingred$target)[c])
  }
  else{
    temp = paste(temp, levels(train_100_freq_ingred$target)[c],sep =  " + ")  
  }
}
temp <- paste(temp, "~")

n <- names(train_100_freq_ingred)
f <- as.formula(paste(temp, paste(n[!n %in% "target"], collapse = " + ")))
now <- Sys.time()
nn<-neuralnet(f,data=trainData,hidden=c(10,10),linear.output=F, algorithm = 'backprop', learningrate = 0.01)
difftime(Sys.time(), now, units = "secs")
res <- compute(nn, test100)

```

